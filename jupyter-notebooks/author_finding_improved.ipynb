{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from math import sqrt\n",
    "\n",
    "class AuthorCandidate:\n",
    "    def __init__(self,\n",
    "                 candidate_string,\n",
    "                 stop_word_confidence = 0,\n",
    "                 author_list_confidence = 0,\n",
    "                 known_name_confidence = 0,\n",
    "                 known_title_confidence = 0,\n",
    "                 name_pattern_confidence = 0,\n",
    "                 name_word_count_confidence = 0,\n",
    "                 digit_word_count_confidence = 0):\n",
    "        self.candidate_string = candidate_string\n",
    "        \n",
    "        self.stop_word_confidence = stop_word_confidence\n",
    "        self.author_list_confidence = author_list_confidence\n",
    "        self.known_name_confidence = known_name_confidence\n",
    "        self.known_title_confidence = known_title_confidence\n",
    "        self.name_pattern_confidence = name_pattern_confidence\n",
    "        self.name_word_count_confidence = name_word_count_confidence\n",
    "        self.digit_word_count_confidence = digit_word_count_confidence\n",
    "        \n",
    "    def score(self):\n",
    "        return (self.stop_word_confidence * 10) \\\n",
    "            + (self.author_list_confidence * 0) \\\n",
    "            + (self.known_name_confidence * 4) \\\n",
    "            + (self.known_title_confidence * 4) \\\n",
    "            + (self.name_pattern_confidence * 2) \\\n",
    "            + (self.name_word_count_confidence * .5) \\\n",
    "            + (self.digit_word_count_confidence * 1)\n",
    "    \n",
    "    def confidence(self):\n",
    "        return 1 - (1 / sqrt(max(self.score(), 1)))\n",
    "    \n",
    "    def calculate_confidences(self, stop_words, first_names):\n",
    "        self.calculate_stop_word_confidence(stop_words)\n",
    "        self.calculate_author_list_confidence()\n",
    "        self.calculate_author_pattern_confidence()\n",
    "        self.calculate_known_name_confidence(first_names)\n",
    "        self.calculate_known_title_confidence()\n",
    "        self.calculate_name_word_count_confidence()\n",
    "        self.calculate_digit_word_count_confidence()\n",
    "    \n",
    "    def calculate_stop_word_confidence(self, stop_words):\n",
    "        'if one stop word is included, the specific confidence becomes 0, otherwise 1'\n",
    "        self.stop_word_confidence = 0\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in self.candidate_string.casefold():\n",
    "                self.stop_word_confidence -= 1\n",
    "        \n",
    "    def calculate_author_list_confidence(self):\n",
    "        'calculates a confidence matching author lists by counting commas and \"and\"s'\n",
    "        self.author_list_confidence = sum([self.candidate_string.count(delimiter) for delimiter in [',', 'and']])\n",
    "        \n",
    "    def calculate_author_pattern_confidence(self):\n",
    "        'based on whether or not the words e.g. begin with an uppercase letter'\n",
    "        self.name_pattern_confidence = 0\n",
    "        if len(self.candidate_string) > 0 and all(map(lambda x: x[0].isupper(), self.candidate_string.replace('and', '').split())):\n",
    "            self.name_pattern_confidence = 1\n",
    "        if sum(1 for c in self.candidate_string if c.isupper()) == 0:\n",
    "            self.name_pattern_confidence = -1\n",
    "    \n",
    "    def calculate_known_name_confidence(self, first_names):\n",
    "        'based on whether or not the candidate includes an entry from a list of known names; name set has to be lowercase'\n",
    "        # remove digits and split at commas and 'and's\n",
    "        self.known_name_confidence = 0\n",
    "        for word in re.split(r' |,|and', ''.join([i for i in self.candidate_string if not i.isdigit()])):\n",
    "            if word and word[0].isupper():\n",
    "                if len(word) == 2 and word[1] == '.':\n",
    "                    self.known_name_confidence += 1\n",
    "                elif word.strip().casefold() in first_names:\n",
    "                    self.known_name_confidence += 1\n",
    "                    \n",
    "    def calculate_known_title_confidence(self):\n",
    "        'based on whether or not the candidate includes an entry from a list of known titles, like Dr., or Prof.'\n",
    "        # remove digits and split at commas and 'and's\n",
    "        self.known_title_confidence = 0\n",
    "        known_titles = {'dr.', 'prof.', 'b.sc.', 'phd', 'ph.d.', 'dphil'}\n",
    "        for word in re.split(r' |,|and', ''.join([i for i in self.candidate_string if not i.isdigit()])):\n",
    "            if word.casefold() in known_titles:\n",
    "                self.known_title_confidence += 1\n",
    "                    \n",
    "    def calculate_name_word_count_confidence(self):\n",
    "        '''based on the number of words the candidate consists of, a confidence is calculated.\n",
    "        Normaly a name consists of two words (first and last name) but some more words are also common (multiple first names)'''\n",
    "        word_count = sum(1 for word in self.candidate_string.split() if len(word) > 0 and word[0].isalpha())\n",
    "        if word_count < 2:\n",
    "            self.name_word_count_confidence = -4\n",
    "        elif word_count == 2:\n",
    "            self.name_word_count_confidence = 4\n",
    "        elif word_count == 3:\n",
    "            self.name_word_count_confidence = 3\n",
    "        elif word_count == 4:\n",
    "            self.name_word_count_confidence = 1\n",
    "        elif word_count == 5:\n",
    "            self.name_word_count_confidence = 0\n",
    "        else:\n",
    "            self.name_word_count_confidence = -2\n",
    "            \n",
    "    def calculate_digit_word_count_confidence(self):\n",
    "        '''based on the number of digits in the words of the candidate a confidence is calculated.\n",
    "        Normaly a name does not includ digits, but through the PDF to Text procedure footnote referenced are part of some candidates'''\n",
    "        for word in self.candidate_string.split():\n",
    "            digit_count = sum(1 for c in word if c.isdigit())\n",
    "            if digit_count < 2:\n",
    "                self.digit_word_count_confidence += 0\n",
    "            elif digit_count == 2:\n",
    "                self.digit_word_count_confidence += -1\n",
    "            elif digit_count == 3:\n",
    "                self.digit_word_count_confidence += -2\n",
    "            else:\n",
    "                self.digit_word_count_confidence += -4\n",
    "            \n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'AuthorCandidate(' + str(round(self.confidence(), 3)) + ' \\'' + self.candidate_string + '\\' [' + \\\n",
    "                 str(self.stop_word_confidence) + ' ' + \\\n",
    "                 str(self.author_list_confidence) + ' ' + \\\n",
    "                 str(self.known_name_confidence) + ' ' + \\\n",
    "                 str(self.known_title_confidence) + ' ' + \\\n",
    "                 str(self.name_pattern_confidence) + ' ' + \\\n",
    "                 str(self.name_word_count_confidence) + ' ' + \\\n",
    "                 str(self.digit_word_count_confidence) + ']' + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_input(text):\n",
    "    '''\n",
    "    returns a list of AuthorCandidates, preprocessed by ignoring\n",
    "    blank lines and merging multi line entries\n",
    "    '''\n",
    "    author_candidates = []\n",
    "    current_entry = ''\n",
    "    for line in text.split('\\n')[:5]:\n",
    "        for chunk in re.split(r',| and ', line):\n",
    "            author_candidates.append(AuthorCandidate(chunk.strip()))\n",
    "        \n",
    "    return author_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthorCandidate(0.0 'MoReBikeS - Model reuse with bike rental' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'station data' [0 0 0 0 -1 4 0])\n",
      "AuthorCandidate(0.5 'Meelis Kull1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Nicolas Lachiche2' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.646 'Adolfo Martı́nez-Usó3' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 '1' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Model Reuse with Subgroup Discovery' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.646 'Hao Song' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Peter Flach' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 'Intelligent Systems Laboratory' [-1 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 'University of Bristol' [-1 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.5 'United Kingdom' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '{Hao.Song' [0 0 0 0 0 -4 0])\n",
      "AuthorCandidate(0.0 'Peter.Flach}@bristol.ac.uk' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'SVR-based Modelling for the MoReBikeS' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.5 'Challenge: Analysis' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Visualisation and' [0 1 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 'Prediction' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.646 'Yu Chen' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Peter Flach' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 'University of Bristol' [-1 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.5 'United Kingdom' [0 0 0 0 1 4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Prediction of Bike Rental using Model Reuse Strategy' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.465 'Arun Bala Subramaniyan' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.5 'Rong Pan' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 'School of Computing' [-1 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.0 'Informatics' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.465 'Decision Systems Engineering' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Arizona State University' [-1 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 'Tempe' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'USA.' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 '{bsarun' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'rong.pan}@asu.edu' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Artificial Neural Networks Applied to' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.465 'Taxi Destination Prediction' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.574 'Alexandre de Brébisson1' [0 1 1 0 0 3 0])\n",
      "AuthorCandidate(0.646 'Étienne Simon2' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Alex Auvolat3' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.622 'Pascal Vincent14' [0 0 1 0 1 4 -1])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Yoshua Bengio14 .' [0 0 0 0 0 4 -1])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.423 'An Ensemble Learning Approach for the Kaggle' [0 0 1 0 0 -2 0])\n",
      "AuthorCandidate(0.293 'Taxi Travel Time Prediction Challenge' [0 0 0 0 1 0 0])\n",
      "AuthorCandidate(0.646 'Thomas Hoch' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.293 'Software Competence Center Hagenberg GmbH' [0 0 0 0 1 0 0])\n",
      "AuthorCandidate(0.0 'Softwarepark 21' [0 0 0 0 0 -4 -1])\n",
      "AuthorCandidate(0.0 '4232 Hagenberg' [0 0 0 0 0 -4 -4])\n",
      "AuthorCandidate(0.0 'Austria' [0 0 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.293 '(Blue) Taxi Destination' [0 0 0 0 0 4 0])\n",
      "AuthorCandidate(0.5 'Trip Time' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 'Prediction from Partial Trajectories' [0 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.635 'Hoang Thanh Lam' [0 0 1 0 1 3 0])\n",
      "AuthorCandidate(0.646 'Ernesto Diaz-Aviles' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.5 'Alessandra Pascale' [0 1 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Yiannis Gkoufas' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.5 'Bei Chen' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.184 'IBM Research – Ireland' [0 1 0 0 0 3 0])\n",
      "\n",
      "AuthorCandidate(0.0 'On learning from taxi-GPS traces' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.5 'João Mendes-Moreira1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Luı́s Moreira-Matias2' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '1' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '1' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Managing Change in Graph-structured Data' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.465 'Using Description Logics' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.646 'Diego Calvanese' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.465 'KRDB Research Centre' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Free University of Bozen-Bolzano' [-1 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.0 'Italy' [0 0 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'STIDS 2015' [0 0 0 0 0 -4 -4])\n",
      "AuthorCandidate(0.0 'The Tenth International Conference on' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.0 'Semantic Technology for Intelligence' [0 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.0 'Defense' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Security' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Semantics in Cyber-Physical Systems' [0 0 0 0 0 1 0])\n",
      "\n",
      "AuthorCandidate(0.5 'Invited Speaker' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.635 'November 19: Dr. Mark Hartong' [0 0 1 1 0 1 -1])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.293 'Positive Train Control Critical Infrastructure' [0 0 0 0 1 0 0])\n",
      "AuthorCandidate(0.0 'Positive Train Control (PTC) is a supervisory control' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'data acquisition system designed to protect against loss' [0 0 0 0 -1 -2 0])\n",
      "AuthorCandidate(0.0 'of locomotive crew situational awareness that could result in train-to-train collision' [0 0 0 0 -1 -2 0])\n",
      "AuthorCandidate(0.0 'train derailments due to excessive speed' [0 0 0 0 -1 -2 0])\n",
      "AuthorCandidate(0.0 'train incursion into roadway work zones' [0 0 0 0 -1 -2 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'train movements through misaligned switches. Multiple' [0 0 0 0 0 -2 0])\n",
      "\n",
      "AuthorCandidate(0.5 'Invited Speaker' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.635 'November 19: Dr. Bruno Sinopoli' [0 0 1 1 0 1 -1])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'On the Security of Cyber-Physical Systems' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'Cyber Physical Systems (CPS) refer to the embedding of widespread sensing' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'computation' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'communication' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'and' [0 1 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'control into physical spaces. Application areas are as diverse as aerospace' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'chemical processes' [0 0 0 0 -1 4 0])\n",
      "AuthorCandidate(0.0 'civil infrastructure' [0 0 0 0 -1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.5 'Invited Speaker' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.635 'November 20: Dr. Alexander Kott' [0 1 1 1 0 1 -1])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'The Unbearable Lightness in the Meaning of Cyber Risk' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'The term “cyber risk” aims to characterize a variety of phenomena where information assets are subject to a potential damage due to cyber attacks. Many attempts' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'almost unblemished by success' [0 0 0 0 -1 1 0])\n",
      "AuthorCandidate(0.0 'have been made to define cyber' [0 0 0 0 -1 -2 0])\n",
      "AuthorCandidate(0.0 'risk. In this talk we explore why the concept of cyber risk' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'as treated by both practitioners' [0 0 0 0 -1 0 0])\n",
      "AuthorCandidate(0.0 'researchers of cyber' [0 0 0 0 -1 3 0])\n",
      "\n",
      "AuthorCandidate(0.5 'Invited Speaker' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.635 'November 20: Dr. James Momoh' [0 0 1 1 0 1 -1])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.465 'Resilient Power Grids' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 'Smart grid system deployment has been a major point of concern' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'interest in the development of the future electric grid both here in the US' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'abroad. Variety of definitions' [0 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.0 'semantics' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'interpretations of its functionality have' [0 0 0 0 -1 0 0])\n",
      "AuthorCandidate(0.0 'been given by designers' [0 0 0 0 -1 1 0])\n",
      "AuthorCandidate(0.0 'implementers' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'end users' [0 0 0 0 -1 4 0])\n",
      "AuthorCandidate(0.0 'standard' [0 1 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'security organizations' [0 0 0 0 -1 4 0])\n",
      "AuthorCandidate(0.0 'university communities.' [-1 0 0 0 -1 4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'A Semantic Approach to Reachability Matrix' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'Computation' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.705 'Nicole Dalia Cilia' [0 0 2 0 1 3 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.646 'Noemi Scarpato' [0 0 1 0 1 4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Approved for Public Release; Distribution Unlimited: 88ABW-2015-2881' [0 0 0 0 0 -2 -4])\n",
      "AuthorCandidate(0.0 '08 Jun 2015' [0 0 0 0 0 -4 -5])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Joint Doctrine Ontology: A Benchmark for Military' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.465 'Information Systems Interoperability' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.646 'Peter Morosoff' [0 0 1 0 1 4 0])\n",
      "\n",
      "AuthorCandidate(0.465 'Automated Ontology Creation' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 'using XML Schema Elements' [0 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.635 'Samuel Suhas Singapogu' [0 0 1 0 1 3 0])\n",
      "AuthorCandidate(0.691 'Paulo C. G. Costa' [0 0 2 0 1 1 0])\n",
      "AuthorCandidate(0.705 'J. Mark Pullen' [0 0 2 0 1 3 0])\n",
      "AuthorCandidate(0.293 'C4I center' [0 0 0 0 0 4 0])\n",
      "AuthorCandidate(0.184 'George Mason University' [-1 0 2 0 1 3 0])\n",
      "AuthorCandidate(0.0 'Fairfax' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'VA' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'USA' [0 0 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'A Probabilistic Ontology for Large-Scale IP' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'Geolocation' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.635 'Kathryn Blackmond Laskey' [0 0 1 0 1 3 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.5 'Sudhanshu Chandekar' [0 1 0 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Bernd-Peter Paris' [0 0 1 0 1 4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Towards a Human Factors Ontology' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.184 'for Cyber Security' [0 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.5 'Alessandro Oltramari' [0 1 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 'Carnegie Mellon University' [-1 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 'Pittsburgh' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'USA' [0 0 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Ontology-based Adaptive Systems of Cyber Defense' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.5 'Noam Ben-Asher⇤‡' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Alessandro Oltramari†' [0 1 0 0 1 4 0])\n",
      "AuthorCandidate(0.705 'Robert F. Erbacher⇤' [0 0 2 0 1 3 0])\n",
      "AuthorCandidate(0.646 'Cleotilde Gonzalez†' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 '⇤ U.S.' [0 0 0 0 0 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Army Research Laboratory Adelphi' [-1 0 0 0 1 1 0])\n",
      "AuthorCandidate(0.0 'MD' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'USA' [0 0 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Enabling New Technologies for Cyber Security' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'Defense with the ICAS Cyber Security Ontology' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.635 'Malek Ben Salem' [0 0 1 0 1 3 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.646 'Chris Wacek' [0 0 1 0 1 4 0])\n",
      "\n",
      "AuthorCandidate(0.0 '1' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Similarity in Semantic Graphs: Combining' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.0 'Structural' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'Literal' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Ontology-based' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'Measures' [0 0 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Towards an Operational Semantic Theory of Cyber' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.293 'Defense Against Advanced Persistent Threats' [0 0 0 0 1 0 0])\n",
      "AuthorCandidate(0.646 'Steven Meckl' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Gheorghe Tecuci' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Mihai Boicu' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Dorin Marcu' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.465 'Learning Agents Center' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 'Volgenau School of Engineering' [-1 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.184 'George Mason University' [-1 0 2 0 1 3 0])\n",
      "AuthorCandidate(0.0 'Fairfax' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'VA 22030' [0 0 0 0 0 -4 -4])\n",
      "AuthorCandidate(0.0 'USA' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'smeckl@masonlive.gmu.edu' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'teuci@gmu.edu' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'mboicu@gmu.edu' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'dmarcu@gmu.edu' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.293 'Genetic Counseling Using Workflow-based EMRs' [0 0 0 0 1 0 0])\n",
      "AuthorCandidate(0.646 'Bo Yu⇤' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Duminda Wijesekera⇤' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.293 'Paulo Costa †' [0 0 0 0 0 4 0])\n",
      "AuthorCandidate(0.5 'Sharath Hiremagalore⇤' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '⇤ Department' [-1 0 0 0 0 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Controlled' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'Uncontrolled English for Ontology' [0 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.0 'Editing' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.646 'Brian Donohue' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.646 'Robert Ganger' [0 0 1 0 1 4 0])\n",
      "\n",
      "AuthorCandidate(0.5 'Toward Representing' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 'Recognizing' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'Cyber-Physical Elements in Competition Using' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.5 'Event Semantics' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Alonza Mumford' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Duminda Wijesekera' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Paulo Costa' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.184 'George Mason University' [-1 0 2 0 1 3 0])\n",
      "\n",
      "AuthorCandidate(0.465 'Linked Logainm: Publishing' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.293 'Using an' [0 0 0 0 0 4 0])\n",
      "AuthorCandidate(0.423 'Authoritative Linked Data Dataset of Irish' [0 0 1 0 0 -2 0])\n",
      "AuthorCandidate(0.5 'Place Names' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Christophe Debruyne' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 'ADAPT Centre for Digital Content Technology Research' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.293 'Knowledge & Data' [0 0 0 0 0 4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'A Quantitative Survey on the Use of the Cube' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'Vocabulary in the Linked Open Data Cloud' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.646 'Karin Becker1' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Shiva Jahangiri2' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.705 'Craig A. Knoblock2' [0 0 2 0 1 3 0])\n",
      "AuthorCandidate(0.0 '1' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Connectedness' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'Meaning:' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'New Analytical Directions for Official Statistics*' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.646 'Frederic Clarke' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Chien-Hung Chien' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 'Australian Bureau of Statistics' [-1 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.184 'Keywords: Semantic statistics' [0 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.0 'linked data' [0 0 0 0 -1 4 0])\n",
      "AuthorCandidate(0.0 'network analysis' [0 0 0 0 -1 4 0])\n",
      "AuthorCandidate(0.184 'linked employeremployee database (LEED)' [0 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.0 'Australian Bureau of Statistics (ABS)' [-1 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.0 'Graphically' [0 0 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Linked Edit Rules: A Web Friendly Way of' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'Checking Quality of RDF Data Cubes' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.646 'Albert Meroño-Peñuela1' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 '2' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.5 'Christophe Guéret2' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.646 'Stefan Schlobach1' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 '1' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'SemNExT: A Framework for Semantically' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.0 'Integrating' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.465 'Exploring Numeric Analyses' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.705 'Evan W. Patton1' [0 0 2 0 1 3 0])\n",
      "AuthorCandidate(0.646 'Elisabeth Brown2' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Matthew Poegel2' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.635 'Hannah De Los' [0 0 1 0 1 3 0])\n",
      "AuthorCandidate(0.5 'Santos2' [0 0 1 0 1 -4 0])\n",
      "AuthorCandidate(0.646 'Chris Fasano3' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.746 'Kristin P. Bennett1' [0 0 3 0 1 3 0])\n",
      "AuthorCandidate(0.0 '2' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.705 'Deborah L. McGuinness1' [0 0 2 0 1 3 0])\n",
      "AuthorCandidate(0.0 '1' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Toward a framework for statistical' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.0 'data integration' [0 0 0 0 -1 4 0])\n",
      "AuthorCandidate(0.5 'Ba-Lam Do' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.465 'Peb Ruswono Aryan' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.646 'Tuan-Dat Trinh' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.646 'Peter Wetz' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Elmar Kiesling' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.635 'A Min Tjoa' [0 0 1 0 1 3 0])\n",
      "AuthorCandidate(0.646 'TU Wien' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 'Vienna' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'Austria' [0 0 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Modeling the Statistical Process with Linked Metadata' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.5 'Franck Cotton' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.705 'Daniel W. Gillman' [0 0 2 0 1 3 0])\n",
      "AuthorCandidate(0.0 'INSEE' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.5 'Paris' [0 0 1 0 1 -4 0])\n",
      "AuthorCandidate(0.5 'France' [0 0 1 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'franck.cotton@insee.fr' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'US Bureau of Labor Statistics' [-2 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.0 'Washington' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'USA' [0 0 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Challenges on Developing Tools for Exploiting Linked' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.465 'Open Data Cubes' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.5 'Evangelos Kalampokis1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '2' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.646 'Bill Roberts3' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Areti Karamanou1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '2' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Efthimios' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'Tambouris1' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 '2' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.5 'Konstantinos Tarabanis1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '2' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '1' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Finding' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'Avoiding Bugs in Enterprise Ontologies' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.646 'Michael Uschold' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 'uschold@semanticarts.com' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.465 'Semantic Arts Inc.' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'A Two-Fold Quality Assurance Approach for Dynamic' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'Knowledge Bases: The 3cixty Use Case' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.5 'Nandana Mihindukulasooriya1' [0 1 0 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Giuseppe Rizzo2' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Raphaël Troncy3' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Oscar Corcho1' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.465 'and Raúl Garcı́a-Castro1' [0 1 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 '1' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'BIR 2016 Workshop on Bibliometric-enhanced Information Retrieval' [0 0 0 0 0 -2 -4])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Editorial for the 3rd Bibliometric-Enhanced' [0 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.0 'Information Retrieval Workshop at ECIR 2016' [0 0 0 0 0 0 -4])\n",
      "AuthorCandidate(0.5 'Philipp Mayr1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Ingo Frommholz2' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.5 'Guillaume Cabanac3' [0 0 0 0 1 4 0])\n",
      "\n",
      "AuthorCandidate(0.0 '3rd International Workshop on News Recommendation and' [0 1 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'Analytics (INRA 2015)' [0 0 0 0 0 -4 -4])\n",
      "AuthorCandidate(0.635 'Jon Atle Gulla' [0 0 1 0 1 3 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.646 'Bei Yu' [0 0 1 0 1 4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Ontology Materialization by Abstraction Refinement in' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.5 'Horn SHOIF' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Birte Glimm' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Yevgeny Kazakov' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.646 'Trung-Kien Tran' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 'University of Ulm' [-1 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.0 'Germany' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 '<first name>.<last name>@uni-ulm.de' [0 0 0 0 -1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Managing Change in Graph-structured Data' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.465 'Using Description Logics' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.646 'Diego Calvanese' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.465 'KRDB Research Centre' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 'Free University of Bozen-Bolzano' [-1 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.0 'Italy' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'calvanese@inf.unibz.it' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Lifted Inference in Probabilistic Databases' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.646 'Dan Suciu' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 'University of Washington' [-1 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.0 'USA' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'suciu@cs.washington.edu' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.5 'Giuliano Armano' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Alessandro Bozzon' [0 1 0 0 1 4 0])\n",
      "AuthorCandidate(0.293 'Alessandro Giuliani (Eds.)' [0 1 0 0 0 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'Proceedings of the 1st International Workshop on' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'Knowledge Discovery on the WEB' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.5 'Extending FrameNet' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 'to Machine Learning Domain' [0 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.5 'Piotr Jakubowski1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Agnieszka Lawrynowicz1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 'Institute of Computing Science' [-2 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.0 'Poznan University of Technology' [-1 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.0 'Poland' [0 1 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 '{pjakubowski' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'alawrynowicz}@cs.put.poznan.pl' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'PageRank on Wikipedia: Towards General' [0 0 0 0 0 0 0])\n",
      "AuthorCandidate(0.0 'Importance Scores for Entities' [0 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.646 'Andreas Thalhammer' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Achim Rettinger' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 'AIFB' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'Karlsruhe Institute of Technology' [-1 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.0 '{andreas.thalhammer' [0 1 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'achim.rettinger}@kit.edu' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Learning semantic rules for intelligent transport' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'scheduling in hospitals' [0 0 0 0 -1 3 0])\n",
      "AuthorCandidate(0.5 'Pieter Bonte' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Femke Ongenae' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.465 'Filip De Turck' [0 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.184 'IBCN research group' [0 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.0 'INTEC department' [-1 0 0 0 0 4 0])\n",
      "AuthorCandidate(0.0 'Ghent University - iMinds' [-1 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.0 'Pieter.Bonte@intec.ugent.be' [0 0 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'The Linked Data Mining Challenge 2016' [0 0 0 0 0 0 -4])\n",
      "AuthorCandidate(0.5 'Petar Ristoski1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Heiko Paulheim1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Vojtěch Svátek2' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.5 'Václav Zeman2' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '1' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'University of Mannheim' [-1 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.0 'Germany' [0 0 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Not-So-Linked Solution to the Linked Data' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.0 'Mining Challenge 2016' [0 0 0 0 0 4 -4])\n",
      "AuthorCandidate(0.5 'Jedrzej Potoniec' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 'Institute of Computing Science' [-2 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.0 'Poznan University of Technology' [-1 0 0 0 0 1 0])\n",
      "AuthorCandidate(0.293 'ul. Piotrowo 2' [0 0 0 0 0 4 0])\n",
      "AuthorCandidate(0.0 '60-965 Poznan' [0 0 0 0 0 -4 -4])\n",
      "AuthorCandidate(0.0 'Poland' [0 1 0 0 1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'A Hybrid Method for Rating Prediction Using Linked' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.5 'Data Features' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Text Reviews' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Semih Yumusak1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '2' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.5 'Emir Muñoz2' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '3' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.646 'Pasquale Minervini2' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Erdogan Dogdu4' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.5 'Halife Kodaz5' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '1' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.0 'Can you judge a music album by its cover?' [0 0 0 0 0 -2 0])\n",
      "AuthorCandidate(0.5 'Petar Petrovski1' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.705 'Anna Lisa Gentile1' [0 0 2 0 1 3 0])\n",
      "AuthorCandidate(0.0 'Data' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 'Web Science Group' [-1 0 0 0 1 3 0])\n",
      "AuthorCandidate(0.0 'University of Mannheim' [-1 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.0 'Germany' [0 0 0 0 1 -4 0])\n",
      "AuthorCandidate(0.0 '{petar' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 'annalisa}@informatik.uni-mannheim.de' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n",
      "AuthorCandidate(0.184 'Results of the' [0 0 0 0 0 3 0])\n",
      "AuthorCandidate(0.0 'Ontology Alignment Evaluation Initiative 2015?' [0 0 0 0 0 1 -4])\n",
      "AuthorCandidate(0.646 'Michelle Cheatham1' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Zlatan Dragisic2' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Jérôme Euzenat3' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Daniel Faria4' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.5 'Alfio Ferrara5' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Giorgos Flouris6' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Irini Fundulaki6' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Roger Granada7' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "AuthorCandidate(0.646 'Valentina Ivanova2' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Ernesto Jiménez-Ruiz8' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.646 'Patrick Lambrix2' [0 0 1 0 1 4 0])\n",
      "AuthorCandidate(0.5 'Stefano Montanelli5' [0 0 0 0 1 4 0])\n",
      "AuthorCandidate(0.0 '' [0 0 0 0 -1 -4 0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if __name__ == '__main__':\n",
    "    stop_words = 'bureau univ school department institut ltd science labor'.split()\n",
    "    # first names borrowed from http://www.quietaffiliate.com/free-first-name-and-last-name-databases-csv-and-sql/\n",
    "    with open('first_names.csv') as file:\n",
    "        first_names = {name.strip().casefold() for name in file.read().split('\\n')[1:]}\n",
    "    texts = []\n",
    "    text_dir = './PDF-Archiv/'\n",
    "    for file in sorted(os.listdir(text_dir))[0:50]:\n",
    "        with open(text_dir + file, encoding='UTF-8') as file:\n",
    "            texts.append(file.read())\n",
    "    for text in texts:\n",
    "        for candidate in preprocess_input(text):\n",
    "            candidate.calculate_confidences(stop_words, first_names)\n",
    "            print(candidate)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
