{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class AuthorCandidate:\n",
    "    def __init__(self, candidate_string, stop_word_confidence = 1, author_list_confidence = 0, known_name_confidence = 0):\n",
    "        self.candidate_string = candidate_string\n",
    "        \n",
    "        self.stop_word_confidence = stop_word_confidence\n",
    "        self.author_list_confidence = author_list_confidence\n",
    "        self.known_name_confidence = known_name_confidence\n",
    "        \n",
    "    def score(self):\n",
    "        return self.stop_word_confidence * ((self.author_list_confidence + 1) * (self.known_name_confidence + 1))\n",
    "    \n",
    "    def calculate_confidences(self, stop_words, first_names):\n",
    "        self.calculate_stop_word_confidence(stop_words)\n",
    "        if self.stop_word_confidence:\n",
    "            # further confidences will only be calculated if the candidate is not already disqualified\n",
    "            self.calculate_author_list_confidence()\n",
    "            self.calculate_author_pattern_confidence()\n",
    "            self.calculate_known_name_confidence(first_names)\n",
    "    \n",
    "    def calculate_stop_word_confidence(self, stop_words):\n",
    "        'if one stop word is included, the specific confidence becomes 0, otherwise 1'\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in self.candidate_string.casefold():\n",
    "                self.stop_word_confidence = 0\n",
    "                return\n",
    "        self.stop_word_confidence = 1\n",
    "        \n",
    "    def calculate_author_list_confidence(self):\n",
    "        'calculates a confidence matching author lists by counting commas and \"and\"s'\n",
    "        self.author_list_confidence = sum([self.candidate_string.count(delimiter) for delimiter in [',', 'and']])\n",
    "        \n",
    "    def calculate_author_pattern_confidence(self):\n",
    "        'based on whether or not the words e.g. begin with an uppercase letter'\n",
    "        pass\n",
    "    \n",
    "    def calculate_known_name_confidence(self, first_names):\n",
    "        'based on whether or not the candidate includes an entry from a list of known names; name set has to be lowercase'\n",
    "        # remove digits and split at commas and 'and's\n",
    "        self.known_name_confidence = 0\n",
    "        for word in re.split(r' |,|and', ''.join([i for i in self.candidate_string if not i.isdigit()])):\n",
    "            if word.strip().casefold() in first_names:\n",
    "                self.known_name_confidence += 1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'AuthorCandidate(\\'' + self.candidate_string + '\\', ' + str(self.score()) +')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_input(text):\n",
    "    '''\n",
    "    returns a list of AuthorCandidates, preprocessed by ignoring\n",
    "    blank lines and merging multi line entries\n",
    "    '''\n",
    "    author_candidates = []\n",
    "    current_entry = ''\n",
    "    for line in text.split('\\n')[:5]:\n",
    "        current_entry += ' ' + line\n",
    "        if current_entry.strip() and not line.endswith((',', 'and')):\n",
    "            author_candidates.append(AuthorCandidate(current_entry.strip()))\n",
    "            current_entry = ''\n",
    "    if current_entry.strip():\n",
    "        author_candidates.append(AuthorCandidate(current_entry.strip()))\n",
    "    return author_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthorCandidate('Decision Making through Polarized', 1)\n",
      "AuthorCandidate('Summarization of User Reviews', 1)\n",
      "AuthorCandidate('Paolo Cremonesi <paolo.cremonesi@polimi.it>, Franca Garzotto <franco.garzotto@polimi.it>, Matteo Guarnerio <matteo.guarnerio@mail.polimi.it>,', 4)\n",
      "\n",
      "AuthorCandidate('Linked Edit Rules: A Web Friendly Way of', 1)\n",
      "AuthorCandidate('Checking Quality of RDF Data Cubes', 1)\n",
      "AuthorCandidate('Albert Meroño-Peñuela1,2 , Christophe Guéret2 , and Stefan Schlobach1', 15)\n",
      "AuthorCandidate('1', 1)\n",
      "\n",
      "AuthorCandidate('Modeling the Statistical Process with Linked Metadata', 1)\n",
      "AuthorCandidate('Franck Cotton and Daniel W. Gillman', 4)\n",
      "AuthorCandidate('INSEE, Paris, France', 9)\n",
      "AuthorCandidate('franck.cotton@insee.fr', 1)\n",
      "AuthorCandidate('US Bureau of Labor Statistics, Washington, USA', 0)\n",
      "\n",
      "AuthorCandidate('What is Special about Bethlehem, Pennsylvania?', 2)\n",
      "AuthorCandidate('Identifying Unexpected Facts about DBpedia Entities', 1)\n",
      "AuthorCandidate('Benjamin Schäfer, Petar Ristoski, and Heiko Paulheim', 8)\n",
      "AuthorCandidate('University of Mannheim, Germany', 0)\n",
      "AuthorCandidate('Research Group Data and Web Science', 2)\n",
      "\n",
      "AuthorCandidate('FRanCo – A Ground Truth Corpus for', 1)\n",
      "AuthorCandidate('Fact Ranking Evaluation', 1)\n",
      "AuthorCandidate('Tamara Bobić, Jörg Waitelonis, and Harald Sack', 8)\n",
      "AuthorCandidate('Hasso-Plattner-Institute, Prof.-Dr.-Helmert-Str. 2-3,', 3)\n",
      "\n",
      "AuthorCandidate('The Curse of Finiteness: Undecidability of', 1)\n",
      "AuthorCandidate('Database-Inspired Reasoning Problems in', 2)\n",
      "AuthorCandidate('Very Expressive Description Logics?', 1)\n",
      "AuthorCandidate('Sebastian Rudolph', 3)\n",
      "AuthorCandidate('TU Dresden', 2)\n",
      "\n",
      "AuthorCandidate('Reasoning in a Rational Extension of SROEL(u, ×)', 4)\n",
      "AuthorCandidate('(Extended Abstract)', 1)\n",
      "AuthorCandidate('Laura Giordano and Daniele Theseider Dupré', 6)\n",
      "AuthorCandidate('DISIT - Università del Piemonte Orientale, Alessandria, Italy', 0)\n",
      "AuthorCandidate('laura.giordano@uniupo.it, dtd@di.unipmn.it', 2)\n",
      "\n",
      "AuthorCandidate('Data accuracy as knowledge in ontology based data', 2)\n",
      "AuthorCandidate('access (preliminary report)', 1)\n",
      "AuthorCandidate('Marco Console', 2)\n",
      "AuthorCandidate('Dipartimento di Ing. Informatica, Automatica e Gestionale “Antonio Ruberti”', 2)\n",
      "AuthorCandidate('S APIENZA Università di Roma', 0)\n",
      "\n",
      "AuthorCandidate('Learning the Role and Behavior of Users in', 4)\n",
      "AuthorCandidate('Group Decision Making', 1)\n",
      "AuthorCandidate('Dimitris Sacharidis1 , Amra Delic1 , and Julia Neidhardt1', 8)\n",
      "AuthorCandidate('E-Commerce Group', 1)\n",
      "AuthorCandidate('Technische Universität Wien, Austria,', 0)\n",
      "\n",
      "AuthorCandidate('StoryBlink', 1)\n",
      "AuthorCandidate('a Semantic Web Approach for Linking Stories', 1)\n",
      "AuthorCandidate('Ben De Meester, Tom De Nies, Laurens De Vocht, Ruben Verborgh, Erik Mannens, and Rik Van de Walle', 42)\n",
      "AuthorCandidate('Ghent University – iMinds – Multimedia Lab, Belgium', 0)\n",
      "\n",
      "AuthorCandidate('Lily Results for OAEI 2015', 2)\n",
      "AuthorCandidate('Wenyu Wang1,2 , Peng Wang1', 3)\n",
      "AuthorCandidate('1', 1)\n",
      "AuthorCandidate('School of Computer Science and Engineering, Southeast University, China', 0)\n",
      "\n",
      "AuthorCandidate('InsMT+ Results for OAEI 2015 Instance Matching', 1)\n",
      "AuthorCandidate('Abderrahmane Khiat1 , Moussa Benaissa1', 2)\n",
      "AuthorCandidate('LITIO Laboratory, University of Oran1 Ahmed Ben Bella, Oran, Algeria', 0)\n",
      "AuthorCandidate('abderrahmane khiat@yahoo.com , moussabenaissa@yahoo.fr', 2)\n",
      "\n",
      "AuthorCandidate('On learning from taxi-GPS traces', 1)\n",
      "AuthorCandidate('João Mendes-Moreira1 and Luı́s Moreira-Matias2', 2)\n",
      "AuthorCandidate('1', 1)\n",
      "AuthorCandidate('1', 1)\n",
      "\n",
      "AuthorCandidate('Linked Data for Libraries: A Project Update', 1)\n",
      "AuthorCandidate('Dean B. Krafft', 2)\n",
      "AuthorCandidate('Cornell University Library, Ithaca, NY', 0)\n",
      "AuthorCandidate('dean.krafft@cornell.edu', 1)\n",
      "\n",
      "AuthorCandidate('Is Query Inseparability for ALC Ontologies Decidable?', 1)\n",
      "AuthorCandidate('E. Botoeva,1 C. Lutz,2 V. Ryzhikov,1 F. Wolter3 and M. Zakharyaschev4', 5)\n",
      "AuthorCandidate('1', 1)\n",
      "AuthorCandidate('1', 1)\n",
      "\n",
      "AuthorCandidate('Enhancing Dataset Quality Using Keys', 1)\n",
      "AuthorCandidate('Tommaso Soru, Edgard Marx, and Axel-Cyrille Ngonga Ngomo', 8)\n",
      "AuthorCandidate('{tsoru,marx,ngonga}@informatik.uni-leipzig.de', 6)\n",
      "AuthorCandidate('AKSW, Department of Computer Science, University of Leipzig', 0)\n",
      "\n",
      "AuthorCandidate('Theoretically Optimal Datalog Rewritings for', 1)\n",
      "AuthorCandidate('OWL 2 QL Ontology-Mediated Queries', 1)\n",
      "AuthorCandidate('M. Bienvenu1, S. Kikot2, R. Kontchakov2, V. Podolskii3, and M. Zakharyaschev2', 6)\n",
      "AuthorCandidate('1', 1)\n",
      "\n",
      "AuthorCandidate('Invited Speaker, November 19: Dr. Mark Hartong', 4)\n",
      "AuthorCandidate('Positive Train Control Critical Infrastructure', 1)\n",
      "AuthorCandidate('Positive Train Control (PTC) is a supervisory control and data acquisition system designed to protect against loss', 2)\n",
      "AuthorCandidate('of locomotive crew situational awareness that could result in train-to-train collision, train derailments due to excessive speed, train incursion into roadway work zones, and train movements through misaligned switches. Multiple', 10)\n",
      "\n",
      "AuthorCandidate('Design Criteria to Model Groups in Big Data', 2)\n",
      "AuthorCandidate('Scenarios: Algorithms and Best Practices?', 2)\n",
      "AuthorCandidate('Ludovico Boratto, Gianni Fenu, and Pier Luigi Pau', 8)\n",
      "AuthorCandidate('Dipartimento di Matematica e Informatica, Università di Cagliari, Via Ospedale 72 - 09124 Cagliari, Italy', 0)\n",
      "\n",
      "AuthorCandidate('Ontologies and the Cultural Heritage. The case of GO!', 2)\n",
      "AuthorCandidate('1', 1)\n",
      "AuthorCandidate('1', 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if __name__ == '__main__':\n",
    "    stop_words = 'bureau univ school department'.split()\n",
    "    with open('first_names.csv') as file: # first names stolen from http://www.quietaffiliate.com/free-first-name-and-last-name-databases-csv-and-sql/\n",
    "        first_names = set([name.strip().casefold() for name in file.read().split('\\n')[1:]])\n",
    "    texts = []\n",
    "    text_dir = './texts/'\n",
    "    for file in sorted(os.listdir(text_dir))[0:20]:\n",
    "        with open(text_dir + file) as file:\n",
    "            texts.append(file.read())\n",
    "    for text in texts:\n",
    "        for candidate in preprocess_input(text):\n",
    "            candidate.calculate_confidences(stop_words, first_names)\n",
    "            print(candidate)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
